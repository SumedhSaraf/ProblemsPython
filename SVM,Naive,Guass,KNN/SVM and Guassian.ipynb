{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold, cross_val_score, train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns',2500)\n",
    "df = pd.read_csv(\"Cleanedoutput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29761, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "Y1 = df[\"target\"]\n",
    "Y = Y1.values\n",
    "df1 = df.drop(\"target\",1)\n",
    "X = df1.values\n",
    "names = list(df.columns)\n",
    "names.pop(0)\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X,Y)\n",
    " \n",
    "print(\"Features sorted by their rank:\")\n",
    "features = list(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0286, 'ps_calc_02'),\n",
       " (0.029100000000000001, 'ps_calc_07'),\n",
       " (0.0304, 'ps_calc_03'),\n",
       " (0.031, 'ps_calc_08'),\n",
       " (0.0315, 'ps_calc_13'),\n",
       " (0.036499999999999998, 'ps_ind_15'),\n",
       " (0.036999999999999998, 'ps_calc_14'),\n",
       " (0.038800000000000001, 'ps_calc_11'),\n",
       " (0.039800000000000002, 'ps_calc_10'),\n",
       " (0.053499999999999999, 'ps_car_14'),\n",
       " (0.064799999999999996, 'ps_reg_03'),\n",
       " (0.0717, 'ps_car_13')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_tuple_list = features[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [x[1] for x in feature_tuple_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list.append(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29761, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y1 = df[\"target\"]\n",
    "Y = Y1.values\n",
    "df1 = df.drop(\"target\",1)\n",
    "X = df1.values\n",
    "FF = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= .4, random_state=0)\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear', C=1).fit(X, Y)\n",
    "sm = svc.fit(X_train, y_train)\n",
    "y_pred = sm.predict(X_test)\n",
    "print(\"Accuracy score using SVM is %s\" %metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acuracy for SVM  is better between Decision classifier and KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "X = MinMaxScaler().fit_transform(FF)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= .4, random_state=0)\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear', C=1).fit(X, Y)\n",
    "sm = svc.fit(X_train, y_train)\n",
    "y_pred = sm.predict(X_test)\n",
    "print(\"Accuracy score using SVM is %s\" %metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling does not change accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Normalizer().fit_transform(FF)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= .4, random_state=0)\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear', C=1).fit(X, Y)\n",
    "sm = svc.fit(X_train, y_train)\n",
    "y_pred = sm.predict(X_test)\n",
    "print(\"Accuracy score using SVM is %s\" %metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing does not change accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = df1.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= .4, random_state=0)\n",
    "nb = GaussianNB()\n",
    "NBm = nb.fit(X_train, y_train)\n",
    "y_pred = NBm.predict(X_test)\n",
    "print(\"Accuracy score using Naive Bayes is %s\" %metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does not perform that great when compared to other 3 algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = MinMaxScaler().fit_transform(FF)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= .4, random_state=0)\n",
    "nb = GaussianNB()\n",
    "NBm = nb.fit(X_train, y_train)\n",
    "y_pred = NBm.predict(X_test)\n",
    "print(\"Accuracy score using Naive Bayes is %s\" %metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy does not change by scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = Normalizer().fit_transform(FF)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= .4, random_state=0)\n",
    "nb = GaussianNB()\n",
    "NBm = nb.fit(X_train, y_train)\n",
    "y_pred = NBm.predict(X_test)\n",
    "print(\"Accuracy score using Naive Bayes is %s\" %metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acuracy increases by normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best algorithm is Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
